# üç∑ Clasificaci√≥n de la Calidad del Vino - Machine Learning Supervisado

**Autor**: Cristian Murillo  
**Dataset**: Extra√≠do de [Kaggle](https://www.kaggle.com/datasets/yasserh/wine-quality-dataset)

---

## üìå Descripci√≥n del Problema

La industria vin√≠cola busca constantemente mejorar la calidad de sus productos. Un modelo de clasificaci√≥n de calidad permitir√≠a identificar qu√© caracter√≠sticas fisicoqu√≠micas afectan la percepci√≥n de calidad y ayudar√≠a a optimizar el proceso de producci√≥n.

El objetivo de este proyecto es dise√±ar un clasificador que prediga la calidad del vino basado en sus propiedades qu√≠micas.

---

## üìÇ Dataset

El archivo utilizado es `wine quality.csv`, el cual contiene **6,497 muestras** con las siguientes variables:

- `fixed acidity`  
- `volatile acidity`  
- `citric acid`  
- `residual sugar`  
- `chlorides`  
- `free sulfur dioxide`  
- `total sulfur dioxide`  
- `density`  
- `pH`  
- `sulphates`  
- `alcohol`  

La variable objetivo es `quality`, una variable discreta en el rango [1, 10], aunque en la pr√°ctica, la mayor√≠a de los valores est√°n entre 3 y 8. Este es un problema de **clasificaci√≥n multiclase**.

---

## üß± Contenido del Proyecto

1. Configuraci√≥n del Ambiente
2. An√°lisis Exploratorio de Datos
    - Valores nulos
    - Duplicados
3. Preprocesamiento
    - Mapeo de clases
    - Remoci√≥n de la clase 9 por falta de muestras
4. Modelamiento Base
5. Selecci√≥n de Modelo
    - Construcci√≥n de Pipelines
    - Reescalado de variables
    - Remuestreo (SMOTE)
    - B√∫squeda de hiperpar√°metros
    - Validaci√≥n cruzada estratificada
6. An√°lisis de Resultados
7. Conclusiones y Recomendaciones

---

## üöÄ Modelamiento Base

Se construy√≥ un modelo inicial para establecer expectativas y validar la metodolog√≠a. La **m√©trica principal de evaluaci√≥n** fue el **F1 Macro**, m√°s robusta ante desbalance de clases en comparaci√≥n con la `accuracy`.

---

## ü§ñ Selecci√≥n de Modelo

Se evaluaron m√∫ltiples clasificadores usando pipelines completos con reescalado y, opcionalmente, remuestreo:

### üìä Modelos Evaluados

- `LogisticRegression`
- `DecisionTreeClassifier`
- `RandomForestClassifier`
- `XGBClassifier`
- `MLPClassifier` (Red neuronal multicapa)

### üîÑ Componentes del Pipeline

- **Imputaci√≥n**: `SimpleImputer` por seguridad en caso de valores faltantes futuros.
- **Estandarizaci√≥n**: `StandardScaler`.
- **Remuestreo**: con `SMOTE`, para mitigar el desbalance de clases.
- **Validaci√≥n Cruzada**: `StratifiedKFold`.
- **Optimizaci√≥n**: `RandomizedSearchCV` (200 combinaciones).

### üìå Hiperpar√°metros evaluados

- Pesos por clase (`class_weight='balanced'`)
- Par√°metros de regularizaci√≥n (`C`, `reg_lambda`)
- Solvers (`liblinear`, `lbfgs`, `saga`)
- Funciones de activaci√≥n (`relu`, `logistic`)
- N√∫mero de estimadores, profundidad m√°xima, tasa de aprendizaje
- Re-muestreo (`SMOTE(k_neighbors=3, 4, 5)`)

### üèÜ Mejor Modelo

```python
Best Parameters:
{
  'sampling': SMOTE(k_neighbors=3, random_state=50),
  'sampling__k_neighbors': 4,
  'model': RandomForestClassifier(random_state=50),
  'model__n_estimators': 200,
  'model__max_depth': 20,
  'model__min_samples_split': 2,
  'model__class_weight': 'balanced'
}
```

## üìà Resultados y Observaciones
* **Random Forest** fue el modelo con mejor desempe√±o, seguido por `XGBoost, MLPClassifier, DecisionTree, y por √∫ltimo LogisticRegression`.
* El modelo tuvo mejor desempe√±o en las clases 5, 6 y 7 ‚Äî las m√°s representadas en el conjunto de datos.
* La clase 9 fue eliminada debido a solo contar con 5 instancias, lo que hace inviable un aprendizaje significativo incluso con SMOTE.
* Se observaron a√∫n altos niveles de falsos positivos y negativos, lo que indica margen de mejora.

---

## ‚úÖ Conclusiones y Recomendaciones
* El desbalance de clases afect√≥ significativamente el rendimiento de los modelos.
* La m√©trica `f1_macro` fue adecuada para evaluar de forma justa el desempe√±o general.
* Para mejorar el rendimiento:
    * Recolectar m√°s datos, especialmente para clases poco representadas.
    * Explorar t√©cnicas de cost-sensitive learning o focal loss.
    * Probar modelos m√°s complejos o espec√≠ficos como CatBoost o TabNet.
    * Considerar t√©cnicas de ensemble para combinar lo mejor de cada modelo.
* Seleccionar la m√©trica de evaluaci√≥n basada en el objetivo de negocio (ej. priorizar recall vs. precision en casos de control de calidad).
---

## üîß Librer√≠as Utilizadas
| Categor√≠a              | Librer√≠as                                                                                                  |
| ---------------------- | ---------------------------------------------------------------------------------------------------------- |
| Procesamiento de datos | `pandas`, `numpy`, `matplotlib`, `seaborn`                                                                 |
| Preprocesamiento       | `SimpleImputer`, `StandardScaler`, `SMOTE`, `Pipeline`                                                     |
| Modelos                | `LogisticRegression`, `RandomForestClassifier`, `DecisionTreeClassifier`, `XGBClassifier`, `MLPClassifier` |
| Evaluaci√≥n             | `classification_report`, `f1_score`, `confusion_matrix`, `ConfusionMatrixDisplay`                          |
| Optimizaci√≥n           | `RandomizedSearchCV`, `StratifiedKFold`                                                                    |
